import streamlit as st
import json
import time
import requests
import pdfplumber
import re
import io

# --- Configuration de la page ---
st.set_page_config(
    page_title="Extracteur R√©el de Relev√©s de Propri√©t√©",
    page_icon="üìÑ",
    layout="wide"
)

# --- Fonctions d'Extraction R√©elle ---

def clean_extracted_text(text):
    """Nettoie le texte des sauts de ligne inutiles pour faciliter la d√©tection."""
    if not text:
        return ""
    # On garde les espaces mais on r√©duit les r√©p√©titions de sauts de ligne
    return re.sub(r'\n+', '\n', text)

def extract_data_from_pdf(pdf_file, target_section):
    """
    Extrait r√©ellement les donn√©es d'un fichier PDF import√©.
    Optimis√© pour capturer les titulaires et adresses sur plusieurs lignes.
    """
    extracted_results = []
    
    with pdfplumber.open(pdf_file) as pdf:
        full_text_pages = []
        for page in pdf.pages:
            full_text_pages.append(page.extract_text() or "")
        
        raw_text = "\n".join(full_text_pages)
        
        # 1. Extraction des titulaires (Noms et Pr√©noms)
        # On cherche "Nom:" suivi du texte jusqu'au prochain champ ou saut de ligne double
        noms_found = re.findall(r"Nom:\s*([A-Z\s\-]+)", raw_text, re.IGNORECASE)
        prenoms_found = re.findall(r"Pr√©nom:\s*([A-Z\s\-]+)", raw_text, re.IGNORECASE)
        
        unique_owners = []
        for n, p in zip(noms_found, prenoms_found):
            full_name = f"{n.strip()} {p.strip()}".replace('\n', ' ')
            if full_name not in unique_owners:
                unique_owners.append(full_name)
        
        titulaire = " & ".join(unique_owners) if unique_owners else "Non d√©tect√©"
        
        # 2. Extraction de l'adresse (souvent apr√®s le pr√©nom ou sous "Adresse:")
        # On cherche le bloc adresse qui commence par "Adresse:" et finit avant "Droit r√©el" ou "Propri√©t√©"
        adresse_titulaire = "Non d√©tect√©e"
        adresse_match = re.search(r"Adresse:\s*(.*?)(?=Droit r√©el|Propri√©t√©|Identification|Page|$)", raw_text, re.DOTALL | re.IGNORECASE)
        if adresse_match:
            # On nettoie les sauts de ligne pour avoir une adresse sur une seule ligne
            adresse_titulaire = adresse_match.group(1).replace('\n', ' ').strip()
            # On supprime les espaces multiples
            adresse_titulaire = re.sub(r'\s+', ' ', adresse_titulaire)

        # 3. Analyse ligne par ligne pour les lots
        lines = raw_text.split('\n')
        
        for i, line in enumerate(lines):
            # Detection de la section (ex: "AS" ou AS)
            # On cherche la section de mani√®re isol√©e ou entre guillemets
            if re.search(rf'"{target_section}"|\b{target_section}\b', line):
                # On scanne les lignes environnantes pour trouver les mots cl√©s LOT et la quote-part
                context = " ".join(lines[max(0, i-2):i+8])
                
                # Cherche les lots (ex: LOT 0000237) et les fractions (ex: 53/10000)
                # Regex adapt√©e √† la structure du document : "LOT 0000237 53/10000"
                lots_found = re.findall(r"LOT\s*(\d+)\s*(\d+/\d+)", context)
                
                for lot_num, qp in lots_found:
                    # √âvite les doublons de lots dans le m√™me fichier
                    if not any(r['lot'] == lot_num for r in extracted_results):
                        extracted_results.append({
                            "proprietaire": titulaire,
                            "adresse": adresse_titulaire,
                            "lot": lot_num,
                            "quotePart": qp,
                            "section": target_section,
                            "plan": "D√©tect√©"
                        })

    return extracted_results

def call_gemini_analysis(data):
    """Appelle l'API Gemini pour analyser les donn√©es extraites."""
    api_key = "" # Fournie par l'environnement
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key={api_key}"
    
    system_prompt = (
        "Tu es un analyste de donn√©es immobili√®res expert. "
        "Synth√©tise ces donn√©es de relev√©s de propri√©t√© en fran√ßais. "
        "Fais un r√©sum√© des biens, des propri√©taires et des quotes-parts."
    )
    
    payload = {
        "contents": [{"parts": [{"text": json.dumps(data)}]}],
        "systemInstruction": {"parts": [{"text": system_prompt}]}
    }
    
    try:
        response = requests.post(url, json=payload, timeout=30)
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text']
    except:
        pass
    return "L'analyse intelligente n'est pas disponible pour le moment."

# --- Interface Streamlit ---

st.title("Extracteur Intelligent de Relev√©s (PDF R√©el) üìÑ")

with st.sidebar:
    st.header("Filtrage")
    section_target = st.text_input("Section √† extraire (ex: AS, CE)", value="AS").strip().upper()
    st.info(f"L'extracteur va scanner le document pour trouver la section {section_target}.")

uploaded_files = st.file_uploader("Chargez vos relev√©s de propri√©t√© (PDF)", type="pdf", accept_multiple_files=True)

if st.button("Analyser les documents"):
    if not uploaded_files:
        st.error("Veuillez charger au moins un fichier PDF.")
    else:
        all_data = []
        
        with st.status("Extraction des informations (Noms, Adresses, Lots)...", expanded=True) as status:
            for uploaded_file in uploaded_files:
                st.write(f"Analyse en profondeur de : {uploaded_file.name}...")
                data = extract_data_from_pdf(uploaded_file, section_target)
                all_data.extend(data)
            
            status.update(label="Extraction termin√©e !", state="complete", expanded=False)

        if all_data:
            st.success(f"Succ√®s : {len(all_data)} lots extraits avec les informations de propri√©t√©.")
            
            # Affichage stylis√©
            st.subheader("Donn√©es Extraites")
            st.table(all_data)
            
            st.subheader("ü§ñ Synth√®se de l'IA")
            with st.spinner("Analyse par Gemini..."):
                analysis = call_gemini_analysis(all_data)
                st.info(analysis)
                
            csv = "Proprietaire;Adresse;Lot;Section;Quote-part\n" + "\n".join([f"{d['proprietaire']};{d['adresse']};{d['lot']};{d['section']};{d['quotePart']}" for d in all_data])
            st.download_button("Exporter en CSV", csv, "extraction_propriete.csv", "text/csv")
        else:
            st.error(f"Aucun lot trouv√© pour la section '{section_target}'.")
            st.info("Note : Assurez-vous que la section demand√©e est bien √©crite en majuscules dans le document (ex: AS).")

st.markdown("---")
st.caption("Version 2.2 - Am√©lioration de la capture multi-lignes des titulaires et adresses")
